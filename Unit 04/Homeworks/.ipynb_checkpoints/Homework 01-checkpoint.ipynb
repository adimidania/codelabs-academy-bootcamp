{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2262123",
   "metadata": {},
   "source": [
    "# Homework 01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12e4b05",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "348f85a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faa8e9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdigits,ydigits = load_digits(n_class=2, return_X_y=True, as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d383f992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xdigits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a77be94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydigits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bdb5952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydigits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d975f743",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(Xdigits, ydigits, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "883b6a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64b2c3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train =y_train.reshape((-1,1))\n",
    "y_test =y_test.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "050838b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "429f8c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(324, 64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a8e76d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(324, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3a76e9",
   "metadata": {},
   "source": [
    "### Functions implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb11e8fa",
   "metadata": {},
   "source": [
    "- We are in front of a Multi-Classification Problem, so in the output layer, we will be having one node for each class using the softmax activation function. And for the loss function we will be using the Categorical Cross-Entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79502be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f420abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLu(x):\n",
    "    return np.maximum(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f3e4177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeParametersHe(InputSize, HiddenLayerSize, OutputSize):\n",
    "    W1 = np.random.randn(HiddenLayerSize, InputSize)* np.sqrt(2/InputSize)\n",
    "    W2 = np.random.randn(OutputSize, HiddenLayerSize)* np.sqrt(2/HiddenLayerSize)\n",
    "    b1 = np.zeros((HiddenLayerSize, 1))\n",
    "    b2 = np.zeros((OutputSize, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1, \"W2\": W2, \"b1\": b1, \"b2\":b2}\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6652dd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardPass(X, Y, parameters):\n",
    "    W1, W2, b1, b2 = parameters[\"W1\"], parameters[\"W2\"], parameters[\"b1\"], parameters[\"b2\"]\n",
    "    Z1 = np.dot(X, W1.T) + b1.T\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(A1, W2.T) + b2.T\n",
    "    A2 = sigmoid(Z2)\n",
    "    cache = (A1, Z1, W1, b1, A2, Z2, W2, b2)\n",
    "    cross_entropies= -(np.multiply(Y, np.log(A2))+np.multiply((1-Y), np.log(1-A2)))\n",
    "    cost= np.sum(cross_entropies)/X.shape[0]\n",
    "    return cost, cache, A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b901b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backwardPass(X, Y, cache):\n",
    "    m = X.shape[0]\n",
    "    (A1, Z1, W1, b1, A2, Z2, W2, b2) = cache\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = np.dot(dZ2.T, A2) / m\n",
    "    db2= np.sum(dZ2.T, axis=1,keepdims=True)\n",
    "    dA1=np.dot(dZ2,W2)\n",
    "    dZ1=np.multiply(dA1, A1*(1 - A1))\n",
    "    dW1=np.dot(dZ1.T, X)/m\n",
    "    db1=np.sum(dZ1.T, axis=1, keepdims=True) /m\n",
    "    \n",
    "    gradients={\"dZ2\":dZ2 , \"dW2\":dW2, \"db2\": db2,\"dZ1\":dZ1 , \"dW1\":dW1 , \"db1\": db1 }\n",
    "    \n",
    "    return gradients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fee8978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradientDescent(parameters, gradients, learningRate):\n",
    "    parameters[\"W1\"]=parameters[\"W1\"] - learningRate * gradients[\"dW1\"]\n",
    "    parameters[\"W2\"]=parameters[\"W2\"] - learningRate * gradients[\"dW2\"]\n",
    "    parameters[\"b1\"]=parameters[\"b1\"] - learningRate * gradients[\"db1\"]\n",
    "    parameters[\"b2\"]=parameters[\"b2\"] - learningRate * gradients[\"db2\"]\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8678cf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X_train,y_train, epochs, learning_rate, parameters):\n",
    "    for i in range(epochs):\n",
    "        loss ,cache, A2 = forwardPass(X_train,y_train ,parameters)\n",
    "        gradients = backwardPass(X_train,y_train, cache)\n",
    "        parameters= GradientDescent(parameters, gradients, learning_rate)\n",
    "        if i % 1000 == 0:\n",
    "            print(\"Loss =\", loss)\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc45e4e",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c6f0ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the weights\n",
    "parameters = initializeParametersHe(X_train.shape[1], 3, y_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "443d9367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.8547324763821659\n",
      "Loss = 0.004570721198697504\n",
      "Loss = 0.006472146689268809\n",
      "Loss = 0.010689065421261653\n",
      "Loss = 0.042672149395356095\n",
      "Loss = 0.006538028978076817\n",
      "Loss = 0.012476084780398577\n",
      "Loss = 0.08591683447899714\n",
      "Loss = 0.007185832560072676\n",
      "Loss = 0.015007065088080038\n"
     ]
    }
   ],
   "source": [
    "parameters = fit(X_train, y_train, 10000, 0.1, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83fb2c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  1.0\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model \n",
    "from sklearn.metrics import accuracy_score\n",
    "_, _, A2= forwardPass(X_test,y_test,parameters )\n",
    "y_test_classes = y_test\n",
    "y_pred_classes = [1 if a>0.5 else 0 for a in A2]\n",
    "print(\"Accuracy = \", accuracy_score(y_test_classes,y_pred_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
